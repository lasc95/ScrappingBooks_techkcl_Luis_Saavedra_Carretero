{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping Luis Saavedra Carretero\n",
    "Este proyecto tiene como finalidad la extracción de data requerida desde la página http://books.toscrape.com/ En la cual se nos solicitó extraer:\n",
    "* 1) el título de los libros\n",
    "* 2) Precio\n",
    "* 3) Stock \n",
    "* 4) Categoría\n",
    "* 5) Carátula del libro (url)\n",
    "* 6) Descripción del libro (\n",
    "    UPC\n",
    "    Product Type\n",
    "    Price (excl. tax)\n",
    "    Price (incl. tax)\n",
    "    Tax\n",
    "    Availability\n",
    "    Number of reviews\n",
    ")\n",
    "<br> <br>\n",
    "Por lo que lo haremos con las siguientes librerías: BeautifulSoup4, requests y regex. <br> <br> <br>\n",
    "Una vez extraída la data, debemos almacenar todos estos datos en un archivo csv; para ello, usaremos la librería pandas para crear un dataFrame y así guardarlo en formato csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: \\ \n",
      "Warning: 4 possible package resolutions (only showing differing packages):\n",
      "  - anaconda/osx-64::ca-certificates-2020.10.14-0, anaconda/osx-64::openssl-1.1.1h-haf1e3a3_0\n",
      "  - anaconda/osx-64::ca-certificates-2020.10.14-0, defaults/osx-64::openssl-1.1.1h-haf1e3a3_0\n",
      "  - anaconda/osx-64::openssl-1.1.1h-haf1e3a3_0, defaults/osx-64::ca-certificates-2020.10.14-0\n",
      "  - defaults/osx-64::ca-certificates-2020.10.14-0, defaults/osx-64::openssl-1.1.1h-haf1e3a3done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/lasc/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pipreqs\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    docopt-0.6.2               |             py_1          14 KB  conda-forge\n",
      "    pipreqs-0.4.10             |             py_0          27 KB  conda-forge\n",
      "    yarg-0.1.9                 |             py_1          13 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:          54 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  docopt             conda-forge/noarch::docopt-0.6.2-py_1\n",
      "  pipreqs            conda-forge/noarch::pipreqs-0.4.10-py_0\n",
      "  yarg               conda-forge/noarch::yarg-0.1.9-py_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  conda              pkgs/main::conda-4.10.1-py38hecd8cb5_1 --> conda-forge::conda-4.10.1-py38h50d1736_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "yarg-0.1.9           | 13 KB     | ##################################### | 100% \n",
      "docopt-0.6.2         | 14 KB     | ##################################### | 100% \n",
      "pipreqs-0.4.10       | 27 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge pipreqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos librerías que vamos a utilizar a lo largo de este proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup as bs \n",
    "import requests as rq \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Obtener contenido de la página principal\n",
    "En esta sección lo que haremos, será crear la variable que contendrá la página principal, donde se encuentran todas las categorías, libros, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recorrer y obtener títulos de libros\n",
    "main_url = 'http://books.toscrape.com/index.html' #página principal\n",
    "page = rq.get(main_url) #obtenemos el requests de la página\n",
    "soup = bs(page.text, 'html.parser') #usamos beautiful soup para leer nuestro html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Creando función getAndParseURL() para obtener todas las páginas en formato óptimo para BeautifulSoup\n",
    "Como podemos percatarnos, tendremos que navegar por muchas páginas durante este proyecto para obtener todos los libros, así que crearemos una función que nos permitirá obtener cualquier página del sitio y leerlo mediante BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos función para obtener cualquier página\n",
    "def getAndParseURL(url):\n",
    "    \"\"\"\n",
    "    Función que tiene como objetivo obtener/parsear cualquier \n",
    "    página, mediante su url\n",
    "    \"\"\"\n",
    "    result = rq.get(url)\n",
    "    soup = bs(result.text, 'html.parser')\n",
    "    return(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Obtener los libros de una determinada url (sección de prueba)\n",
    "Una vez ya adentrado en nuestra página, debemos obtener la información de cada libro en la página que sea. En este caso, vemos que el libro se encuentra dentro de un \"article\" (de html) y con la clase \"product_pod\".\n",
    "Haremos la prueba de obtener solamente el primer producto que encuentre con las características/atributos mencionados anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<article class=\"product_pod\">\n",
       "<div class=\"image_container\">\n",
       "<a href=\"catalogue/a-light-in-the-attic_1000/index.html\"><img alt=\"A Light in the Attic\" class=\"thumbnail\" src=\"media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg\"/></a>\n",
       "</div>\n",
       "<p class=\"star-rating Three\">\n",
       "<i class=\"icon-star\"></i>\n",
       "<i class=\"icon-star\"></i>\n",
       "<i class=\"icon-star\"></i>\n",
       "<i class=\"icon-star\"></i>\n",
       "<i class=\"icon-star\"></i>\n",
       "</p>\n",
       "<h3><a href=\"catalogue/a-light-in-the-attic_1000/index.html\" title=\"A Light in the Attic\">A Light in the ...</a></h3>\n",
       "<div class=\"product_price\">\n",
       "<p class=\"price_color\">Â£51.77</p>\n",
       "<p class=\"instock availability\">\n",
       "<i class=\"icon-ok\"></i>\n",
       "    \n",
       "        In stock\n",
       "    \n",
       "</p>\n",
       "<form>\n",
       "<button class=\"btn btn-primary btn-block\" data-loading-text=\"Adding...\" type=\"submit\">Add to basket</button>\n",
       "</form>\n",
       "</div>\n",
       "</article>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"article\", class_ = \"product_pod\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora podemos obtener la url del libro para así acceder y tomar sus atributos. \n",
    "En este caso haremos una prueba con el primer producto. Ahora vamos a utilizar una función para obtener todas las urls de los libros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'catalogue/a-light-in-the-attic_1000/index.html'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"article\", class_ = \"product_pod\").div.a.get('href')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que haremos será almacenar en una lista todos los href, para ello utilizaremos lo que se conoce como \"List Comprehension\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['catalogue/a-light-in-the-attic_1000/index.html',\n",
       " 'catalogue/tipping-the-velvet_999/index.html',\n",
       " 'catalogue/soumission_998/index.html',\n",
       " 'catalogue/sharp-objects_997/index.html',\n",
       " 'catalogue/sapiens-a-brief-history-of-humankind_996/index.html',\n",
       " 'catalogue/the-requiem-red_995/index.html',\n",
       " 'catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html',\n",
       " 'catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html',\n",
       " 'catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html',\n",
       " 'catalogue/the-black-maria_991/index.html']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_books_urls = [x.div.a.get('href') for x in soup.findAll(\"article\", class_ = 'product_pod')]\n",
    "main_books_urls[:10] #consultaremos los primeros 10 urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora crearemos una función para obtener la información de cualquier libro desde cualquier página (ya que no solo trabajaremos con la página principal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerLibroUrls(url):\n",
    "    \"\"\"\n",
    "    Función para obtener libros desde cualquier página \n",
    "    (de bookstoscrape).\n",
    "    \"\"\"\n",
    "    soup = getAndParseURL(url)\n",
    "    return([\"/\".join(url.split(\"/\")[:-1]) + \"/\" + x.div.a.get('href') for x in soup.findAll(\"article\", class_ = \"product_pod\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Obteniendo las urls de cada categoría\n",
    "Obtendremos las categorías de los libros (url). En esta ocasión, utilizaremos una herramienta que nos será de mucha utilidad, **Regex**, el cual buscaremos un patrón dentro del href que direcciona a las categorías, que en este caso es: **catalogue/category/books/nombre_categoría**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://books.toscrape.com/catalogue/category/books_1/index.html',\n",
       " 'http://books.toscrape.com/catalogue/category/books/travel_2/index.html',\n",
       " 'http://books.toscrape.com/catalogue/category/books/mystery_3/index.html',\n",
       " 'http://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html',\n",
       " 'http://books.toscrape.com/catalogue/category/books/sequential-art_5/index.html']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtenemos categorías\n",
    "categorias_url = [main_url.replace('index.html','') + x.get('href') for x in soup.find_all('a', href = re.compile('catalogue/category/books'))]\n",
    "categorias_url[:5]#consultamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos percatamos que poseemos las urls de todas las categorías, es cosa de copiar una y la pegamos en nuestro navegador para ver que funciona. En el primer elemento, vemos que es el index.html de todos los libros, así que vamos a eliminarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias_url = categorias_url[1:]\n",
    "#quitamos http://books.toscrape.com/catalogue/category/books_1/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categorias_url) #podemos contar las categorías y obtenemos 50 urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Obteniendo el número de páginas \n",
    "Nos hemos percatado que no solo existe una página, sino pueden existir varias (además pueden agregarse durante el tiempo), así que vamos obtener el número de las páginas con la siguiente serie de pasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "paginas_url = [main_url] #creamos una variable donde tendremos nuestras url de las paginas (todas***)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://books.toscrape.com/index.html']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paginas_url #consultamos su contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paginas_url\n",
    "soup = getAndParseURL(paginas_url[0])\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = getAndParseURL(paginas_url[0])#utilizamos nuestra página para leer las demás páginas. \n",
    "#a continuacion vamos a revisar si contiene algún botón que nos lleve a la otra página\n",
    "while len(soup.findAll('a', href = re.compile('page'))) == 2 or len(paginas_url) == 1:\n",
    "    new_url = \"/\".join(paginas_url[-1].split('/')[:-1]) + \"/\" + soup.findAll('a', href = re.compile('page'))[-1].get('href')\n",
    "    paginas_url.append(new_url)\n",
    "    soup = getAndParseURL(new_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paginas_url) #vemos cuantas páginas en total hemos coleccionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://books.toscrape.com/catalogue/page-50.html'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paginas_url[-1]#obtenemos la última y la consultamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Obtener la url de todos los libros en cualquier página.\n",
    "Aquí utilizaremos la funcion de obtenerlibrourls, la cual obtiene los libros según una url entregada. En este caso tenemos 50 urls, y obtendremos todos los libros de esas urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "libros_url = []\n",
    "\n",
    "for page in paginas_url:\n",
    "    libros_url.extend(obtenerLibroUrls(page)) #extendemos desde un iterable como es la obtencion de las urls de los libros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html',\n",
       " 'http://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html',\n",
       " 'http://books.toscrape.com/catalogue/soumission_998/index.html',\n",
       " 'http://books.toscrape.com/catalogue/sharp-objects_997/index.html',\n",
       " 'http://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html',\n",
       " 'http://books.toscrape.com/catalogue/the-requiem-red_995/index.html',\n",
       " 'http://books.toscrape.com/catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html',\n",
       " 'http://books.toscrape.com/catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html',\n",
       " 'http://books.toscrape.com/catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html',\n",
       " 'http://books.toscrape.com/catalogue/the-black-maria_991/index.html']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libros_url[:10] #consultamos los primeros 10 libros y los podemos copiar en nuestro navegador para comprobar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(libros_url)#tenemos un total de 1000 libros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Obteniendo los datos solicitados de los libros\n",
    "Ya estando con todas las urls de los libros, vamos a proceder a obtener la información de ellos. como todos las páginas poseen la misma estructura, será más amable la obtención de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "prices = []\n",
    "stock = []\n",
    "img_urls = []\n",
    "categories = [] \n",
    "ratings = []\n",
    "upc = []\n",
    "type_of = []\n",
    "price_without_tax = []\n",
    "price_with_tax = []\n",
    "tax = []\n",
    "no_reviews = []\n",
    "avl = []\n",
    "#vamos a obtener toda la data de los libros\n",
    "for url in libros_url:\n",
    "    soup = getAndParseURL(url)\n",
    "    #el nombre del producto\n",
    "    names.append(soup.find('div', class_ = re.compile('product_main')).h1.text)\n",
    "    #el precio del producto\n",
    "    #prices.append(soup.find('p', class_ = 'prices_color').text[2:])\n",
    "    #stock del producto\n",
    "    stock.append(re.sub('[^0-9]', '', soup.find('p', class_ = 'instock availability').text))\n",
    "    #img_urls\n",
    "    img_urls.append(url.replace('index.html', '') + soup.find('img').get('src'))\n",
    "    #categoría\n",
    "    categories.append(soup.find('a', href = re.compile('../category/books/')).get('href').split('/')[3])\n",
    "    #ratings \n",
    "    ratings.append(soup.find('p', class_ = re.compile('star-rating')).get('class')[1])\n",
    "    #upc\n",
    "    upc.append(soup.find('table').find('tr').find('td').text)\n",
    "    #tipo del producto\n",
    "    type_of.append(soup.find(\"th\", text=\"Product Type\").find_next_sibling(\"td\").text)\n",
    "    #precio sin impuesto\n",
    "    price_without_tax.append(soup.find(\"th\", text=\"Price (excl. tax)\").find_next_sibling(\"td\").text[1:])\n",
    "    #precio con impuesto\n",
    "    price_with_tax.append(soup.find(\"th\", text=\"Price (incl. tax)\").find_next_sibling(\"td\").text[1:])\n",
    "    #impuesto\n",
    "    tax.append(soup.find(\"th\", text=\"Tax\").find_next_sibling(\"td\").text[1:])\n",
    "    #reviews\n",
    "    no_reviews.append(soup.find(\"th\", text=\"Number of reviews\").find_next_sibling(\"td\").text)\n",
    "    #disponibles\n",
    "    avl.append(soup.find('p', {'class': 'availability'}).getText().replace('\\n', '').strip()[10:12] + ' available')#un poco de manejo de strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a verificar que todos poseen sus nombres y demás atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(libros_url), len(names), len(stock), len(img_urls), len(categories), len(ratings), len(upc), len(type_of), len(price_with_tax), len(price_without_tax), len(tax), len(no_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Almacenando valores en un dataframe y exportando a CSV\n",
    "Una vez obtenidas las listas con los valores que solicitaron en github, podemos crear nuestro dataframe con el formato adecuado que nos solicitaron. Como sabemos, los df se construyen a partir de diccionarios, así que usaremos las llaves (keys) para el nombre de cada columna y las series/listas para rellenar las filas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Category</th>\n",
       "      <th>Cover</th>\n",
       "      <th>UPC</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Price (excl. tax)</th>\n",
       "      <th>Price (incl. tax)</th>\n",
       "      <th>Tax</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Number of reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>£51.77</td>\n",
       "      <td>22</td>\n",
       "      <td>poetry_23</td>\n",
       "      <td>http://books.toscrape.com/catalogue/a-light-in...</td>\n",
       "      <td>a897fe39b1053632</td>\n",
       "      <td>Books</td>\n",
       "      <td>£51.77</td>\n",
       "      <td>£51.77</td>\n",
       "      <td>£0.00</td>\n",
       "      <td>22available</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>£53.74</td>\n",
       "      <td>20</td>\n",
       "      <td>historical-fiction_4</td>\n",
       "      <td>http://books.toscrape.com/catalogue/tipping-th...</td>\n",
       "      <td>90fa61229261140a</td>\n",
       "      <td>Books</td>\n",
       "      <td>£53.74</td>\n",
       "      <td>£53.74</td>\n",
       "      <td>£0.00</td>\n",
       "      <td>20available</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>£50.10</td>\n",
       "      <td>20</td>\n",
       "      <td>fiction_10</td>\n",
       "      <td>http://books.toscrape.com/catalogue/soumission...</td>\n",
       "      <td>6957f44c3847a760</td>\n",
       "      <td>Books</td>\n",
       "      <td>£50.10</td>\n",
       "      <td>£50.10</td>\n",
       "      <td>£0.00</td>\n",
       "      <td>20available</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>£47.82</td>\n",
       "      <td>20</td>\n",
       "      <td>mystery_3</td>\n",
       "      <td>http://books.toscrape.com/catalogue/sharp-obje...</td>\n",
       "      <td>e00eb4fd7b871a48</td>\n",
       "      <td>Books</td>\n",
       "      <td>£47.82</td>\n",
       "      <td>£47.82</td>\n",
       "      <td>£0.00</td>\n",
       "      <td>20available</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>£54.23</td>\n",
       "      <td>20</td>\n",
       "      <td>history_32</td>\n",
       "      <td>http://books.toscrape.com/catalogue/sapiens-a-...</td>\n",
       "      <td>4165285e1663650f</td>\n",
       "      <td>Books</td>\n",
       "      <td>£54.23</td>\n",
       "      <td>£54.23</td>\n",
       "      <td>£0.00</td>\n",
       "      <td>20available</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Title   Price Stock              Category  \\\n",
       "0                   A Light in the Attic  £51.77    22             poetry_23   \n",
       "1                     Tipping the Velvet  £53.74    20  historical-fiction_4   \n",
       "2                             Soumission  £50.10    20            fiction_10   \n",
       "3                          Sharp Objects  £47.82    20             mystery_3   \n",
       "4  Sapiens: A Brief History of Humankind  £54.23    20            history_32   \n",
       "\n",
       "                                               Cover               UPC  \\\n",
       "0  http://books.toscrape.com/catalogue/a-light-in...  a897fe39b1053632   \n",
       "1  http://books.toscrape.com/catalogue/tipping-th...  90fa61229261140a   \n",
       "2  http://books.toscrape.com/catalogue/soumission...  6957f44c3847a760   \n",
       "3  http://books.toscrape.com/catalogue/sharp-obje...  e00eb4fd7b871a48   \n",
       "4  http://books.toscrape.com/catalogue/sapiens-a-...  4165285e1663650f   \n",
       "\n",
       "  Product Type Price (excl. tax) Price (incl. tax)    Tax Availability  \\\n",
       "0        Books            £51.77            £51.77  £0.00  22available   \n",
       "1        Books            £53.74            £53.74  £0.00  20available   \n",
       "2        Books            £50.10            £50.10  £0.00  20available   \n",
       "3        Books            £47.82            £47.82  £0.00  20available   \n",
       "4        Books            £54.23            £54.23  £0.00  20available   \n",
       "\n",
       "  Number of reviews  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Title': names, 'Price': price_with_tax, 'Stock': stock, \"Category\": categories, \n",
    "                             \"Cover\": img_urls, \"UPC\": upc, \"Product Type\": type_of, \"Price (excl. tax)\": price_without_tax,\n",
    "                             \"Price (incl. tax)\" : price_with_tax, \"Tax\" : tax, \"Availability\" : avl, \"Number of reviews\" : no_reviews \n",
    "                            })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1) Un poco de manejo de datos en dataframes \n",
    "Podemos percatarnos que en categorías hay un problema con el nombre de esta (ejemplo mystery_32), vamos a arreglarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in df['Category']:\n",
    "    l.append(i.split('_')[0])\n",
    "df['Category'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Category</th>\n",
       "      <th>Cover</th>\n",
       "      <th>UPC</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Price (excl. tax)</th>\n",
       "      <th>Price (incl. tax)</th>\n",
       "      <th>Tax</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Number of reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>£51.77</td>\n",
       "      <td>22</td>\n",
       "      <td>poetry</td>\n",
       "      <td>http://books.toscrape.com/catalogue/a-light-in...</td>\n",
       "      <td>a897fe39b1053632</td>\n",
       "      <td>Books</td>\n",
       "      <td>£51.77</td>\n",
       "      <td>£51.77</td>\n",
       "      <td>£0.00</td>\n",
       "      <td>22available</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>£53.74</td>\n",
       "      <td>20</td>\n",
       "      <td>historical-fiction</td>\n",
       "      <td>http://books.toscrape.com/catalogue/tipping-th...</td>\n",
       "      <td>90fa61229261140a</td>\n",
       "      <td>Books</td>\n",
       "      <td>£53.74</td>\n",
       "      <td>£53.74</td>\n",
       "      <td>£0.00</td>\n",
       "      <td>20available</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>£50.10</td>\n",
       "      <td>20</td>\n",
       "      <td>fiction</td>\n",
       "      <td>http://books.toscrape.com/catalogue/soumission...</td>\n",
       "      <td>6957f44c3847a760</td>\n",
       "      <td>Books</td>\n",
       "      <td>£50.10</td>\n",
       "      <td>£50.10</td>\n",
       "      <td>£0.00</td>\n",
       "      <td>20available</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>£47.82</td>\n",
       "      <td>20</td>\n",
       "      <td>mystery</td>\n",
       "      <td>http://books.toscrape.com/catalogue/sharp-obje...</td>\n",
       "      <td>e00eb4fd7b871a48</td>\n",
       "      <td>Books</td>\n",
       "      <td>£47.82</td>\n",
       "      <td>£47.82</td>\n",
       "      <td>£0.00</td>\n",
       "      <td>20available</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>£54.23</td>\n",
       "      <td>20</td>\n",
       "      <td>history</td>\n",
       "      <td>http://books.toscrape.com/catalogue/sapiens-a-...</td>\n",
       "      <td>4165285e1663650f</td>\n",
       "      <td>Books</td>\n",
       "      <td>£54.23</td>\n",
       "      <td>£54.23</td>\n",
       "      <td>£0.00</td>\n",
       "      <td>20available</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Title   Price Stock            Category  \\\n",
       "0                   A Light in the Attic  £51.77    22              poetry   \n",
       "1                     Tipping the Velvet  £53.74    20  historical-fiction   \n",
       "2                             Soumission  £50.10    20             fiction   \n",
       "3                          Sharp Objects  £47.82    20             mystery   \n",
       "4  Sapiens: A Brief History of Humankind  £54.23    20             history   \n",
       "\n",
       "                                               Cover               UPC  \\\n",
       "0  http://books.toscrape.com/catalogue/a-light-in...  a897fe39b1053632   \n",
       "1  http://books.toscrape.com/catalogue/tipping-th...  90fa61229261140a   \n",
       "2  http://books.toscrape.com/catalogue/soumission...  6957f44c3847a760   \n",
       "3  http://books.toscrape.com/catalogue/sharp-obje...  e00eb4fd7b871a48   \n",
       "4  http://books.toscrape.com/catalogue/sapiens-a-...  4165285e1663650f   \n",
       "\n",
       "  Product Type Price (excl. tax) Price (incl. tax)    Tax Availability  \\\n",
       "0        Books            £51.77            £51.77  £0.00  22available   \n",
       "1        Books            £53.74            £53.74  £0.00  20available   \n",
       "2        Books            £50.10            £50.10  £0.00  20available   \n",
       "3        Books            £47.82            £47.82  £0.00  20available   \n",
       "4        Books            £54.23            £54.23  £0.00  20available   \n",
       "\n",
       "  Number of reviews  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Exportando a CSV \n",
    "finalmente con nuestro dataFrame creado con el formato requerido, vamos a exportarlo como csv para futuros análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('encargo_scrapping_books_Luis_Saavedra_Carretero.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) creando txt con requerimientos para este proyecto\n",
    "Al estar utilizando Anaconda, utilizo este comando para crear automáticamente los requerimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda list -e > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Conclusiones\n",
    "<br> \n",
    "Ya finalizada esta entrega podemos afirmar que la tarea de web Scrapping es crucial para obtener información relevante. Claramente siempre teniendo ética y respetando las políticas de seguridad (siempre consultando al robot.txt) y además utilizar siempre para fines de mejorar la calidad de los servicios y no para destruir sistemas, etc. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
